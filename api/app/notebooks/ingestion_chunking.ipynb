{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "import openai\n",
    "import llama_index\n",
    "from openai import AzureOpenAI\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.bridge.pydantic import PrivateAttr\n",
    "from typing import Any, List\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"no_proxy\"] = \"10.156.254.10\"\n",
    "openai.api_key = \"dtnumds\"\n",
    "openai.api_base = \"http://10.156.254.10:8000/v1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"dtnumds\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://10.156.254.10:8000/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI( api_key=\"dtnumds\",\n",
    "                azure_endpoint=\"http://10.156.254.10:8000/v1\",\n",
    "                api_version = \"2023-07-01-preview\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in client.models.list().data :\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DGFIPEmbeddings(BaseEmbedding):\n",
    "    _model_name: str = PrivateAttr()\n",
    "    _openai_client = PrivateAttr()\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        openai_client,\n",
    "        model_name: str = \"dgfip-e5-large\",\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        self._model_name = model_name\n",
    "        self._openai_client = openai_client\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"DGFIPEmbedding\"\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        embeddings = self._openai_client.embeddings.create(\n",
    "            input = query,\n",
    "            model= self._model_name # model = \"deployment_name\".\n",
    "        )\n",
    "        return embeddings.data[0].embedding\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        embeddings = self._openai_client.embeddings.create(\n",
    "            input = text,\n",
    "            model= self._model_name # model = \"deployment_name\".\n",
    "        )\n",
    "        return embeddings.data[0].embedding\n",
    "    \n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        embeddings = self._openai_client.embeddings.create(\n",
    "            input = texts,\n",
    "            model= self._model_name # model = \"deployment_name\".\n",
    "        )\n",
    "        embs = [e.embedding for e in embeddings.data]\n",
    "        return embs\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = DGFIPEmbeddings(openai_client = client)\n",
    "Settings.llm  = OpenAILike(model='mixtral-instruct', max_tokens=2048, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    SemanticSplitterNodeParser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1, breakpoint_percentile_threshold=50, embed_model=DGFIPEmbeddings(openai_client = client)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/test_html.csv')\n",
    "df['n_words'] = df.text.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.n_words.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = df.text.to_list()\n",
    "filenames = df.filename.to_list()\n",
    "n_words = df.n_words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(text=contents[i], metadata={\"filename\": filenames[i],\n",
    "                                                \"n_words\": n_words[i]\n",
    "                                                    }) for i in range(len(contents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ayd-ds",
   "language": "python",
   "name": "ayd-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
